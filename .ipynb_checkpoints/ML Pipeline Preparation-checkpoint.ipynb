{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BurgerWu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BurgerWu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BurgerWu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('Disaster_Response_Table', engine)\n",
    "\n",
    "#Create X and Y \n",
    "X = df[\"message\"].values\n",
    "Y = df.iloc[:,4:].values\n",
    "\n",
    "#Retrieve number of labels and label names\n",
    "num_of_labels = Y.shape[1]\n",
    "label_names = df.columns[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build tokenize function\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    This tokenize function processes input text to generate useful word tokens\n",
    "    Input: text content\n",
    "    Output: processed word tokens    \n",
    "    \"\"\"\n",
    "    #Define stop_words and create stemming and lemmatizing objects\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    stemming = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    #First use regular expression to get rid of punctuations\n",
    "    text = re.sub(r'[^a-zA-Z0-9]',' ',text.lower())\n",
    "    \n",
    "    #Then tokenize the text and eliminate stop words\n",
    "    words = word_tokenize(text)\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    #In the last step, process the word token list with lemmitizer and then stemmer\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    stemmed = [PorterStemmer().stem(w) for w in lemmed]\n",
    "   \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries for Ml pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Create pipeline object\n",
    "Original_pipeline = Pipeline(\n",
    "[(\"Vectorizer\",CountVectorizer(tokenizer = tokenize)),\\\n",
    " (\"TFIDF\",TfidfTransformer()),\\\n",
    " (\"Estimator\",MultiOutputClassifier(RandomForestClassifier()))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('Vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split X and Y into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "Original_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856238</td>\n",
       "      <td>0.918491</td>\n",
       "      <td>0.886273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.811133</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.576678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.731555</td>\n",
       "      <td>0.583258</td>\n",
       "      <td>0.649043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.082938</td>\n",
       "      <td>0.144330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.185430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.037975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.058252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.884984</td>\n",
       "      <td>0.439683</td>\n",
       "      <td>0.587487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.796209</td>\n",
       "      <td>0.350731</td>\n",
       "      <td>0.486957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.063492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.147783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.205761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.066845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.115830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.173285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.857282</td>\n",
       "      <td>0.603967</td>\n",
       "      <td>0.708668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.868545</td>\n",
       "      <td>0.417607</td>\n",
       "      <td>0.564024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.384770</td>\n",
       "      <td>0.519621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.898263</td>\n",
       "      <td>0.725451</td>\n",
       "      <td>0.802661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.157407</td>\n",
       "      <td>0.263566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.324737</td>\n",
       "      <td>0.451527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision    recall  f1-score\n",
       "0    0.856238  0.918491  0.886273\n",
       "1    0.811133  0.447368  0.576678\n",
       "2         NaN  0.000000       NaN\n",
       "3    0.731555  0.583258  0.649043\n",
       "4    0.555556  0.082938  0.144330\n",
       "5    0.666667  0.107692  0.185430\n",
       "6    0.750000  0.019481  0.037975\n",
       "7    0.428571  0.031250  0.058252\n",
       "8    0.645161  0.121212  0.204082\n",
       "9         NaN       NaN       NaN\n",
       "10   0.859375  0.318841  0.465116\n",
       "11   0.884984  0.439683  0.587487\n",
       "12   0.796209  0.350731  0.486957\n",
       "13   0.764706  0.156627  0.260000\n",
       "14   0.571429  0.033613  0.063492\n",
       "15   1.000000  0.017544  0.034483\n",
       "16   0.576923  0.084746  0.147783\n",
       "17   0.833333  0.117371  0.205761\n",
       "18   0.462963  0.036023  0.066845\n",
       "19   0.142857  0.006515  0.012461\n",
       "20   0.681818  0.063291  0.115830\n",
       "21   0.705882  0.098765  0.173285\n",
       "22   0.666667  0.042105  0.079208\n",
       "23        NaN  0.000000       NaN\n",
       "24   0.000000  0.000000       NaN\n",
       "25        NaN  0.000000       NaN\n",
       "26        NaN  0.000000       NaN\n",
       "27   0.250000  0.005102  0.010000\n",
       "28   0.857282  0.603967  0.708668\n",
       "29   0.868545  0.417607  0.564024\n",
       "30   0.800000  0.384770  0.519621\n",
       "31   0.000000  0.000000       NaN\n",
       "32   0.898263  0.725451  0.802661\n",
       "33   0.809524  0.157407  0.263566\n",
       "34   0.545455  0.046512  0.085714\n",
       "35   0.740741  0.324737  0.451527"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Report test set results\n",
    "y_pred = Original_pipeline.predict(X_test)\n",
    "\n",
    "Metrics_Original = pd.DataFrame(columns = [\"precision\", \"recall\", \"f1-score\"])\n",
    "\n",
    "for i in range(num_of_labels):\n",
    "    test = y_test[:,i]\n",
    "    predict = y_pred[:,i]\n",
    "    TP = np.sum(np.logical_and(test == 1, predict == 1))\n",
    "    FN = np.sum(np.logical_and(test == 1, predict == 0))\n",
    "    FP = np.sum(np.logical_and(test == 0, predict == 1))\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2*(precision*recall)/(precision + recall)\n",
    "    Metrics_Original = Metrics_Original.append({\"precision\":precision, \"recall\":recall, \"f1-score\":f1_score},ignore_index = True)\n",
    "\n",
    "Metrics_Original  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics_Original.to_csv(\"Metrics_Original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import GridSearch Library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define grid search parameters\n",
    "parameters = {\n",
    "        'Vectorizer__ngram_range': ((1, 1), (1, 2)),\n",
    "        'Vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "        'Vectorizer__max_features': (None, 5000, 10000),\n",
    "        'TFIDF__use_idf': (True, False)}\n",
    "       # 'Estimator__n_estimators': [50, 100, 200],\n",
    "        #'Estimator__min_samples_split': [2, 3, 4]}\n",
    "\n",
    "cv = GridSearchCV(Original_pipeline, param_grid = parameters)\n",
    "\n",
    "#Re-train the model with grid search result\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:1000], Y[:1000], test_size = 0.2)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report test set results after grid search\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "for i in range(num_of_labels):\n",
    "    print(\"Classification Report of \" + label_names[i])\n",
    "    print(classification_report(y_test[:,i], y_pred[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define new custom transformer called Special_Punc_Counter to get average amount of special punctuation per sentence\n",
    "class Special_Puncs_Counter():\n",
    "    #count_special_puncs method is the main method to count special pnctuations\n",
    "    def count_special_puncs(self, text):\n",
    "        \"\"\"\n",
    "        This function analyzes the amount of special punctuations and divide it by number of sentences\n",
    "        Imput: Text to analyze\n",
    "        Output: Calculated special punctuation per sentence\n",
    "        \"\"\"\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        num_sentence = len(sentence_list)\n",
    "        count = 0\n",
    "        for sentence in sentence_list:\n",
    "            puncs = re.findall(r'[!?~<>({:;]',sentence)\n",
    "            count += len(puncs)\n",
    "        return count/num_sentence\n",
    "    \n",
    "    #Define fit method\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    #Define transform method to transform series of interest\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.count_special_puncs)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Feature Union with new custom transformer to our pipeline\n",
    "New_Feature_pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_processing', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('count_special_puncs', Special_Puncs_Counter())\n",
    "        ])),\n",
    "\n",
    "        ('Estimator', RandomForestClassifier())\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.87      0.90        38\n",
      "          1       0.96      0.99      0.97       160\n",
      "          2       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.95      0.95      0.95       200\n",
      "\n",
      "Classification Report of request\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.94      0.93        89\n",
      "          1       0.95      0.94      0.95       111\n",
      "\n",
      "avg / total       0.94      0.94      0.94       200\n",
      "\n",
      "Classification Report of offer\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       200\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "Classification Report of aid_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92        77\n",
      "          1       1.00      0.89      0.94       123\n",
      "\n",
      "avg / total       0.94      0.94      0.94       200\n",
      "\n",
      "Classification Report of medical_help\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       176\n",
      "          1       1.00      0.58      0.74        24\n",
      "\n",
      "avg / total       0.95      0.95      0.94       200\n",
      "\n",
      "Classification Report of medical_products\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       185\n",
      "          1       1.00      0.67      0.80        15\n",
      "\n",
      "avg / total       0.98      0.97      0.97       200\n",
      "\n",
      "Classification Report of search_and_rescue\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       192\n",
      "          1       1.00      0.62      0.77         8\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "Classification Report of security\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       191\n",
      "          1       1.00      0.56      0.71         9\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "Classification Report of military\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       198\n",
      "          1       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.98      0.99      0.99       200\n",
      "\n",
      "Classification Report of child_alone\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       200\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "Classification Report of water\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       168\n",
      "          1       1.00      0.91      0.95        32\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "Classification Report of food\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       149\n",
      "          1       1.00      0.92      0.96        51\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "Classification Report of shelter\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       178\n",
      "          1       1.00      0.73      0.84        22\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "Classification Report of clothing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       196\n",
      "          1       1.00      0.50      0.67         4\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "Classification Report of money\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       197\n",
      "          1       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "Classification Report of missing_people\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       197\n",
      "          1       1.00      0.33      0.50         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "Classification Report of refugees\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       194\n",
      "          1       1.00      0.67      0.80         6\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "Classification Report of death\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       188\n",
      "          1       1.00      0.75      0.86        12\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "Classification Report of other_aid\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93       151\n",
      "          1       1.00      0.55      0.71        49\n",
      "\n",
      "avg / total       0.90      0.89      0.88       200\n",
      "\n",
      "Classification Report of infrastructure_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       187\n",
      "          1       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "Classification Report of transport\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       192\n",
      "          1       1.00      0.62      0.77         8\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "Classification Report of buildings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       188\n",
      "          1       1.00      0.67      0.80        12\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "Classification Report of electricity\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       200\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "Classification Report of tools\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       198\n",
      "          1       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "Classification Report of hospitals\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       197\n",
      "          1       1.00      0.33      0.50         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "Classification Report of shops\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       200\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "Classification Report of aid_centers\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       199\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "Classification Report of other_infrastructure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       191\n",
      "          1       1.00      0.67      0.80         9\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "Classification Report of weather_related\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       172\n",
      "          1       1.00      0.64      0.78        28\n",
      "\n",
      "avg / total       0.95      0.95      0.95       200\n",
      "\n",
      "Classification Report of floods\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       191\n",
      "          1       1.00      0.56      0.71         9\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "Classification Report of storm\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       193\n",
      "          1       1.00      0.71      0.83         7\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "Classification Report of fire\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       200\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "Classification Report of earthquake\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       190\n",
      "          1       1.00      0.50      0.67        10\n",
      "\n",
      "avg / total       0.98      0.97      0.97       200\n",
      "\n",
      "Classification Report of cold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       195\n",
      "          1       1.00      0.60      0.75         5\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "Classification Report of other_weather\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       195\n",
      "          1       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "Classification Report of direct_report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93        92\n",
      "          1       0.96      0.92      0.94       108\n",
      "\n",
      "avg / total       0.94      0.94      0.94       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[:1000], Y[:1000], test_size = 0.2)\n",
    "New_Feature_pipeline.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n",
    "for i in range(num_of_labels):\n",
    "    print(\"Classification Report of \" + label_names[i])\n",
    "    print(classification_report(y_test[:,i], y_pred[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_file = open(\"model.pkl\",'wb')\n",
    "pickle.dump(New_Feature_pipeline, pickle_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
